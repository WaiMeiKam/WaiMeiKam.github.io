---
title: "AI-Native Product Design"
date: "2026-01-22"
teaser: "Designing for AI isn't about slapping a chatbot on your product. It's about rethinking what the interface even is."
tags: ["AI", "product design", "futures"]
---

<SectionLabel>A shift, not a feature</SectionLabel>

## The chatbot trap

Every product team I talk to right now is doing the same thing: taking their existing product, bolting on an AI chat interface, and calling it "AI-powered."

It's the equivalent of putting a search bar on a print catalogue and calling it e-commerce.

The real opportunity with AI isn't about *adding* intelligence to existing flows. It's about **rethinking what the flow is** in the first place.

<KeyInsight title="The question I keep asking">
If this product were invented today — with access to LLMs, vision models, and real-time inference — would it have a form? Would it have a settings page? Would it have a dashboard?
</KeyInsight>

## Three design shifts I'm watching

### 1. From configuration to conversation

Traditional software makes you configure everything upfront. Preferences, settings, filters, sort orders. AI-native products can *infer* most of this from context and let you correct as you go.

Instead of: "Set your notification preferences across these 47 toggles."

Try: "I'll be quiet unless something looks urgent. Tell me if I'm getting it wrong."

### 2. From dashboards to digests

Dashboards assume you know what to look for. They present all the data and leave the synthesis to you. AI-native products can do the synthesis and present **the thing you need to know** — not the 200 metrics you *might* need to know.

The dashboard doesn't go away entirely, but it becomes the drill-down, not the default.

### 3. From static pages to adaptive interfaces

This one's still early, but I reckon it's the biggest shift. Instead of designing one layout that serves everyone, we design **systems of layouts** that adapt based on who's using them and what they're trying to do.

Not just responsive to screen size — responsive to *intent*.

<Callout>
None of this is about removing control from the user. It's about changing the default from "you figure it out" to "here's what I think you need — correct me if I'm wrong."
</Callout>

<SectionLabel>What this means for designers</SectionLabel>

## New muscles to build

If you're a product designer working on AI features, you need some skills that design school didn't teach:

- **Prompt design.** Not prompt engineering in the technical sense, but understanding how to frame instructions to a model so the output is useful. This is a design skill.
- **Failure state design.** AI gets things wrong. A lot. The quality of your product is defined by how gracefully it handles being wrong.
- **Trust calibration.** Users need to know when to trust the AI and when to double-check. That's a UX problem, not a model problem.
- **Evaluation thinking.** You can't just ship and hope. You need to think about how you'll know if the AI is actually helping — and that often means qualitative signals, not just metrics.

<KeyInsight title="My mental model">
Good AI product design is like good management: set the context, suggest a direction, and make it easy for the human to course-correct.
</KeyInsight>

## The opportunity

We're in the messy middle right now. Most AI products are awkward — half-old-paradigm, half-new. That's fine. That's where the interesting design problems are.

The designers who'll define this era aren't the ones who can prompt GPT the best. They're the ones who can **reimagine the interaction model** from first principles, while still shipping something useful today.

---

I'm deeply excited about this space and actively experimenting with it. If you're working on AI product design and want to jam on ideas, I'm always up for a chat.
